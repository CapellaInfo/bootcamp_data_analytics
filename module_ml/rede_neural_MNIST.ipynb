{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ePvmM1OTZfTN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() # Convertendo de imagem para Tensor\n",
        "\n",
        "\n",
        "# Base de dados contendo imagens de números escritos de diversas maneiras\n",
        "# Construção de uma rede neural para distinguir os números\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte destinada a TREINO\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # Carrega a parte destinada a VALIDAÇÃO\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "-dpdWRGdZ7U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7783bd05-e830-4ed0-be97-f1d6640dfd5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 86482377.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 36409886.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 92573539.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7459095.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = dataiter.next()\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmpa='gray_r');"
      ],
      "metadata": {
        "id": "pabsJN21cgPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "9a7f6eaa-d223-4810-a2dd-5d9f34cc1669"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d7f6eb2a7c0e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimagens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metiquetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmpa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) # Verificando as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape)"
      ],
      "metadata": {
        "id": "0Tf0kmsRdjqy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "8f1de3cb-03f2-4c42-882b-721a37e6d3c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'imagens' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-70e6526489c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Verificando as dimensões do tensor de cada imagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metiquetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imagens' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128)\n",
        "    self.linear2 = nn.Linear(128, 64)\n",
        "    self.linear3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self,X):\n",
        "    X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "    X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "    X = self.linear3(X) # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "    return F.log_softmax(X, dim=1) # calculo de perda\n"
      ],
      "metadata": {
        "id": "BkW0EW-VesWC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0, momentum=0.5)\n",
        "  inicio = time() # contagem de quanto tempo levou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() # criterio de calculo de perda\n",
        "  EPOCHS = 10 # número de epochs que o algoritmo rodará\n",
        "  modelo.train() # ativando o mode de treino do modelo\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0])\n",
        "      otimizador.zero_grad()\n",
        "\n",
        "      output = modelo(imagens.to(device))\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "\n",
        "      perda_instantanea.backward()\n",
        "\n",
        "      otimizador.step()\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "    else:\n",
        "        print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) =\", (time()-inicio)/60)\n"
      ],
      "metadata": {
        "id": "sKqS2-vkd8AL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0,0\n",
        "    for imagens, etiquetas in valloader:\n",
        "      for i in range(len(etiquetas)):\n",
        "        img = imagens[i].view(1, 784)\n",
        "        with torch.no_grad():\n",
        "          logps = modelo(img.to(device))\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.cpu().numpy()[0])\n",
        "        etiqueta_pred = probab.index(max(probab))\n",
        "        etiqueta_certa = etiquetas.numpy()[i]\n",
        "        if(etiqueta_certa == etiqueta_pred):\n",
        "          conta_corretas += 1\n",
        "        conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "YJqCirFWLVIo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5MF6xMOMmD-",
        "outputId": "1f61d520-0a14-4fd0-e355-f7a3e8ad9a7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}